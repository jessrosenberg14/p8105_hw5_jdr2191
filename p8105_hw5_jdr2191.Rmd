---
title: "p8105_hw5_jdr2191"
output: github_document
---
```{r load_libraries}
library(tidyverse)
library(viridis)
```

## Problem 1

```{r}
homicide_df = 
  read_csv("./homicides/homicide-data.csv", na = c("", "Unknown")) %>%
  mutate(city_state = str_c(city, state),
         resolution = case_when(
           disposition == "Closed without arrest" ~ "unsolved",
           disposition == "Open/No arrest" ~ "unsolved",
           disposition == "Closed by arrest" ~ "solved"
         )) %>%
  relocate(city_state) %>%
  filter(city_state != "TulsaAL")

homicide_df %>%
  count(city_state) %>% view

```

victim_age: encoded as a character (will want to address)
some other things are listed as NA

The homicide dataset contains `r count(homicide_data)` observations.

Let's look at Baltimore, MD
```{r}
baltimore_df = 
  homicide_df %>%
  filter(city_state == "BaltimoreMD")

baltimore_summary = 
  baltimore_df %>%
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  )

baltimore_test = 
  prop.test(
    x = baltimore_summary %>% pull(unsolved),
    n = baltimore_summary %>% pull(n))

baltimore_test %>%
  broom::tidy()
```
64% were not solved; 95% CI of .627 to .663

Let's try to iterate across cities. 

First off, write a function
```{r}
prop_test_function = function(city_df) {

city_summary = 
  city_df %>% 
  summarize(
      unsolved = sum(resolution == "unsolved"),
      n = n()
  )

city_test = 
  prop.test(x = city_summary %>% pull(unsolved), 
  n = city_summary %>% pull(n))

  return(city_test)
}

prop_test_function(baltimore_df)

homicide_df %>%
  filter(city_state == "AlbuquerqueNM") %>%
  prop_test_function()
```

Now let's iterate across cities
```{r}
results_df = 
  homicide_df %>% 
  nest(data = uid:resolution) %>% 
  mutate(
    test_results = map(data, prop_test_function),
    tidy_results = map(test_results, broom::tidy)
  ) %>% 
  select(city_state, tidy_results) %>% 
  unnest(tidy_results) 
```

Try to make a plot showing estimates and CIs
```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

```{r}
homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  ) %>% 
  mutate(
    test_results = map2(unsolved, n, prop.test), 
    tidy_results = map(test_results, broom::tidy)
  ) %>% 
  select(city_state, tidy_results) %>% 
  unnest(tidy_results) %>% 
  select(city_state, estimate, starts_with("conf"))
```

## Problem 2

```{r}
files_df =
  tibble(
    participants = list.files("data")) %>%
    mutate()

files2_df =
  files_df %>%
  map(function(x) read_csv(file.path("data", x))) %>%
  reduce(rbind)

files2_df =
  files_df %>%
  map(function(file_name) {
    assign(x = str_remove(file_name, ".csv"))
    value = read_csv(paste0("data", file_name)),
    envir = .GlobalEnv
  })

```

Testing out reading in one file:

```{r}
con_01_df = 
  read_csv("data/con_01.csv") 

con_01 = 
  con_01_df %>%
  write.table(con_01, file = sprintf("%s.csv",participant), row.names=FALSE)
  

baltimore_test = 
  prop.test(
    x = baltimore_summary %>% pull(unsolved),
    n = baltimore_summary %>% pull(n))

baltimore_test %>%
  broom::tidy()
```


Write a function
```{r}
read_participants_function = function(participant_df) {

participant_data = 
  participant_df %>% 
  read_csv("data")

participant_test = 
  prop.test(x = participant_data)

  return(participant_test)
}

prop_test_function(baltimore_df)

homicide_df %>%
  filter(city_state == "AlbuquerqueNM") %>%
  prop_test_function()
```

## Problem 3

```{r}
library(tidyverse)

set.seed(10)

iris_with_missing = iris %>%
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

Write a function.

```{r}
fill_in_missing = function(vector) {
  
  if (is.numeric) {
    
    
  }
  
  if (is.character) {
    
    
  }
  
  
  }
  }
  
}
```

we will map across a DF and update each of the columns and put it back together as a DF
